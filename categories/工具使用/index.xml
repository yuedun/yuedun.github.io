<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>工具使用 on 月盾的博客</title>
    <link>https://www.yuedun.wang/categories/%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/</link>
    <description>Recent content in 工具使用 on 月盾的博客</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Sat, 10 Jul 2021 20:15:08 +0800</lastBuildDate><atom:link href="https://www.yuedun.wang/categories/%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Chrome插件hook Ajax</title>
      <link>https://www.yuedun.wang/2021/07/chrome-extensions-hook-ajax/</link>
      <pubDate>Sat, 10 Jul 2021 20:15:08 +0800</pubDate>
      
      <guid>https://www.yuedun.wang/2021/07/chrome-extensions-hook-ajax/</guid>
      <description>如何Hook Ajax请求 现在很多网站都使用Ajax作为数据接口，这样其实也方便爬虫爬取数据，但是，如果站点对IP，访问频率做 了限制，或者网站定位就是搜索类，无法遍历完所有页面，或者是数据实时变化，无法预期的。这样就可能需要 直接在浏览器中模拟人的行为，对于这样的网站(使用Ajax作数据接口，有一定防范措施) ，如果我们可以通过hook得到Ajax请求，就可以搞定它的数据了。
单页面Web应用 对于单页面的Web应用，在console中使用如下代码，就能在浏览器进行Ajax请求时候，得到返回内容， 然后在post给存储接口就好了:
(function() { var origOpen = XMLHttpRequest.prototype.open; XMLHttpRequest.prototype.open = function() { // console.log(&amp;#39;request started!&amp;#39;);  this.addEventListener(&amp;#39;load&amp;#39;, function() { console.log(this.responseText); // 得到Ajax的返回内容  }); origOpen.apply(this, arguments); }; })(); 比如百度图片:
我们可以看到请求图片的路径，这段代码 直接使用了一个匿名函数，重写了Ajax请求的open方法，给load事件加上一个事件监听器，从而把内容得到:
对于单页面的Web应用，基本可以满足需求，但是如果翻页的话，每次翻页上一页的代码就失效了， 不可能每页都把这段代码复制进console中，还是需要使用类似Chrome插件的方式才能实现。
翻页Web应用 有了上面的代码，如果我们把它直接丢到Chrome插件的JS文件里面(官方叫Content Scripts)，发现是无法执行的，XMLHttpRequest.prototype.open 还是浏览器自身的代码。
这样看来，就无法实现自动翻页，自动获取ajax请求内容了。
Chrome官方说法如下:
 Content scripts execute in a special environment called an isolated world. They have access to the DOM of the page they are injected into, but not to any JavaScript variables or functions created by the page.</description>
    </item>
    
    <item>
      <title>七牛在线管理图片预览chrome插件</title>
      <link>https://www.yuedun.wang/2021/07/qiuniu-image-preivew/</link>
      <pubDate>Tue, 06 Jul 2021 19:32:15 +0800</pubDate>
      
      <guid>https://www.yuedun.wang/2021/07/qiuniu-image-preivew/</guid>
      <description>七牛云图片存储有10G的免费额度，对于个人来说足够使用了。使用七牛图片存储涉及到图片上传，查看，管理的问题。为了能提高使用效率，我们可以利用好一些工具。
vscode插件上传图片到七牛 vsocode扩展市场有很多上传到七牛的插件，大家可以根据需要自己选择。上传的图片多了以后，有时需要找一些已经上传的图片来使用，目前我所知道的方法还仅限于登录的七牛后台上查看。
可以看到，七牛的管理后台做的不能说很差，可以说是很气人。要预览图片必须点击“详情”，当你关掉预览窗口时却不知道查看的是哪张图片，也没有个高亮聚焦。而且也买有时间排序，只有名称排序，真的是很难用。
为了能够直观的看到图片，决定开发一款chrome插件，将图片直接显示出来，而不用再点击查看。
关于chrome插件开发的细节本文暂不细说，直接上代码。
代码展示 manifest.json
{ &amp;#34;manifest_version&amp;#34;: 2, &amp;#34;name&amp;#34;: &amp;#34;chome-plugin&amp;#34;, &amp;#34;version&amp;#34;: &amp;#34;0.0.1&amp;#34;, &amp;#34;description&amp;#34;: &amp;#34;chrome示例插件&amp;#34;, &amp;#34;icons&amp;#34;: { &amp;#34;16&amp;#34;: &amp;#34;images/icon-16x16.png&amp;#34;, &amp;#34;48&amp;#34;: &amp;#34;images/icon-48x48.png&amp;#34;, &amp;#34;128&amp;#34;: &amp;#34;images/icon-128x128.png&amp;#34; }, &amp;#34;page_action&amp;#34;: { &amp;#34;default_icon&amp;#34;: { &amp;#34;48&amp;#34;: &amp;#34;images/icon-48x48.png&amp;#34; }, &amp;#34;default_popup&amp;#34;: &amp;#34;html/popup.html&amp;#34;, &amp;#34;default_title&amp;#34;: &amp;#34;Hello yuedun&amp;#34; }, &amp;#34;author&amp;#34;: &amp;#34;yuedun&amp;#34;, &amp;#34;background&amp;#34;: { &amp;#34;scripts&amp;#34;: [ &amp;#34;scripts/jquery.min.js&amp;#34;, &amp;#34;scripts/background.js&amp;#34; ] }, &amp;#34;devtools_page&amp;#34;: &amp;#34;html/devtools-page.html&amp;#34;, &amp;#34;content_scripts&amp;#34;: [ { &amp;#34;js&amp;#34;: [ &amp;#34;scripts/jquery.min.js&amp;#34;, &amp;#34;scripts/content.js&amp;#34; ], &amp;#34;css&amp;#34;: [ &amp;#34;styles/yuedun-insert.css&amp;#34; ], &amp;#34;matches&amp;#34;: [ &amp;#34;https://portal.qiniu.com/kodo/bucket/resource?bucketName=*&amp;#34; ], &amp;#34;run_at&amp;#34;: &amp;#34;document_start&amp;#34; } ], &amp;#34;permissions&amp;#34;: [ &amp;#34;cookies&amp;#34;, &amp;#34;*://*/*&amp;#34;, &amp;#34;webRequest&amp;#34; ], &amp;#34;homepage_url&amp;#34;: &amp;#34;https://www.</description>
    </item>
    
    <item>
      <title>vscode正则查找替换</title>
      <link>https://www.yuedun.wang/blogdetail/5e5a3fb45bd8165f28d21307/</link>
      <pubDate>Mon, 14 Jun 2021 10:40:52 +0000</pubDate>
      
      <guid>https://www.yuedun.wang/blogdetail/5e5a3fb45bd8165f28d21307/</guid>
      <description>查找某一类型字符串： 正则表达式onclick=.*&amp;quot; 会查找到所有： onclick=&amp;quot;_msq.push([&#39;trackEvent&#39;, &#39;210074305d6b0409-09c7759e04e98528&#39;, &#39;&#39;pcpid&#39;, &#39;&#39;]);&amp;quot;
onclick=是固定一样的字符，
.代表除\r和\n之外的任意字符，等价于[^\r\n]
*代表匹配前面的模式 0或多次 {0,}
&amp;quot;这是字符串最后一个字符
在vscode中的效果如下： 至于要替换成什么就看自己需求了，如果要给选中的字符串包裹字符串则需要修改成这样：
查找替换 查找：(onclick=.*&amp;quot;)
替换：aaa($1)
结果：
替换字符串两头，保留中间 两部分文字交换位置 相同模式的文字交换位置。
查找：(\(\d{4}-\d{1,2}-\d{2}\)) (\[.*\))
替换：$2 $1
结果：
vscode中一对括号()代表一个变量。
第一组正则 (\(\d{4}-\d{1,2}-\d{2}\)) 对应 $1，
第二组正则 (\[.*\))对应 $2，以此类推。
所以，可以查找多组数据，在替换部分将两个对应变量交换位置即可。</description>
    </item>
    
    <item>
      <title>typescript不检查node_moduls</title>
      <link>https://www.yuedun.wang/blogdetail/60b48e405caa4b4dc69e3abf/</link>
      <pubDate>Fri, 11 Jun 2021 14:16:17 +0800</pubDate>
      
      <guid>https://www.yuedun.wang/blogdetail/60b48e405caa4b4dc69e3abf/</guid>
      <description>tsconfig.json 中 exclude node_modules，但 tsc 还是报错。
node_modules/connect-mongo/src/types.d.ts:113:66 - error TS2694: Namespace &amp;#39;global.Express&amp;#39; has no exported member &amp;#39;SessionData&amp;#39;. 113 get: (sid: string, callback: (err: any, session: Express.SessionData | null) =&amp;gt; void) =&amp;gt; void; ~~~~~~~~~~~ node_modules/connect-mongo/src/types.d.ts:114:45 - error TS2694: Namespace &amp;#39;global.Express&amp;#39; has no exported member &amp;#39;SessionData&amp;#39;. 114 set: (sid: string, session: Express.SessionData, callback?: (err: any) =&amp;gt; void) =&amp;gt; void; ~~~~~~~~~~~ node_modules/connect-mongo/src/types.d.ts:118:47 - error TS2694: Namespace &amp;#39;global.Express&amp;#39; has no exported member &amp;#39;SessionData&amp;#39;. 118 touch: (sid: string, session: Express.</description>
    </item>
    
    <item>
      <title>朱雀发布系统支持scp（rsync）发布</title>
      <link>https://www.yuedun.wang/blogdetail/60950c9ee76f307341586548/</link>
      <pubDate>Fri, 11 Jun 2021 14:16:17 +0800</pubDate>
      
      <guid>https://www.yuedun.wang/blogdetail/60950c9ee76f307341586548/</guid>
      <description>去年花了三天时间开发了一个简易版的nodejs发布系统，它是基于pm2自带的deploy机制开发的，主要原理就是在两台装有pm2的机器直接通信，并执行相应的命令。再往简单了说就是在发布机上远程执行命令，而朱雀发布系统提供了一个图形界面而已。
当时把这个系统定位为nodejs专用发布系统，因为它依赖了pm2，而pm2则是nodejs专用的进程管理工具，其他语言用不到。这个系统的上线也算是解决了我司一直以来没有合适的nodejs发布系统的空缺。
经过9个月的使用，也算比较稳定。但是也存在问题，最大的问题是部署应用方面比较繁琐。
基本流程如下：
 发布机和应用服务器设置ssh通信配置。 应用服务器安装git（有自带，但是版本太旧）。 配置git用户名，邮箱。 生成ssh公钥。 把应用服务器的公钥配置到git代码服务器上。以便能拉代码。 发布机远程执行git pull来代码操作，各应用服务把代码拉取下来。 执行编译打包操作。 执行重启服务操作。  部署一次系统还是比较麻烦的，如果应用服务器有多台，可能还要重复这样的操作多次，实在比较麻烦。
使用scp同步代码的方式会比较简单一些，但是像nodejs这样的项目，node_module占了很大比重，如果每次都打包的话会拖慢同步速度，而scp又不具备排除文件夹的能力。
最后找到了rsync命令可以满足需求。然后就是基于rsync实现了一版。不用再依赖pm2，应用服务器也不用强制使用git了。
朱雀和Jenkins对比如何？ 要说Jenkins那绝对是持续集成领域的老大哥，自然是功能强大。但是每个团队和产品有其特殊性，Jenkins并不完全适用。而朱雀也有其优势。
 朱雀本身部署简单，使用go开发，不依赖运行时，无需安装，开箱即用。 目前支持和测试过的数据库有sqlite3（目前用的，不需要繁琐的安装过程）和mysql。 配置简单。 部署发布一键完成，不需要单独的部署过程。 并行发布。 审批，通知，权限。 开源，可定制开发。  项目地址：朱雀发布系统</description>
    </item>
    
    <item>
      <title>easy-monitor qps监控</title>
      <link>https://www.yuedun.wang/blogdetail/60861bef54277a10496a54b6/</link>
      <pubDate>Mon, 26 Apr 2021 01:48:31 +0000</pubDate>
      
      <guid>https://www.yuedun.wang/blogdetail/60861bef54277a10496a54b6/</guid>
      <description>Easy-Monitor是一款轻量级的Node性能监控工具，仅仅需要项目入口 require 一次，就可以非常便捷地展示出进程的状态细节。
Easy-Monitor主要提供以下的功能：
 找出执行时长耗费最久的5个或者更多的函数 找出那些执行时间超出预期的函数 找出v8引擎无法优化的函数  Easy-Monitor的特点：
 轻量级：非传统C/S物理分离模式，require 后即可使用，没有额外的监控server/agent部署成本。 运行时：针对的是运行时的函数性能以及内存细节进行处理展示，可用于线上生产环境项目。 无状态：永远展示的是开发者访问时的业务进程状态  关于监控qps，作者在文档中并没有提到qps这样的关键字，很多人也不知道怎么监控qps。 不过在监控界面中有这样的指标数据： 所以我从源码入手，找到了该数据指标的源头是这样的：
const data = { osCpu: Number((used_cpu * 100).toFixed(2)), osMem: Number((used_memory_percent * 100).toFixed(2)), maxDisk: max_disk_usage, disks: disks_json, load1: Number(load1.toFixed(2)), load5: Number(load5.toFixed(2)), load15: Number(load15.toFixed(2)), nodeCount: node_count, scavengeTotal: total_scavange_duration, scavengeAverage: scavange_duration_last_record, marksweepTotal: total_marksweep_duration, marksweepAverage: marksweep_duration_last_record, qps: Number((http_response_sent / 60).toFixed(2)), rtExpired: http_patch_timeout, rtAverage: http_rt, }; 这是接口返回的数据，包含了qps数据，那么qps实际上就是http_response_sent，所以监控中就可以这样设置qps了： @http_response_sent/60 &amp;gt; 10</description>
    </item>
    
    <item>
      <title>firefox火狐新标签中打开书签</title>
      <link>https://www.yuedun.wang/blogdetail/60191322ebffed4856026fc7/</link>
      <pubDate>Tue, 02 Feb 2021 08:53:54 +0000</pubDate>
      
      <guid>https://www.yuedun.wang/blogdetail/60191322ebffed4856026fc7/</guid>
      <description>火狐浏览器新建标签总是在当前打开标签之后，而不是在最后一个标签后新建。 1.about:config 2.browser.tabs.insertAfterCurrent设为false。
新标签中打开书签 browser.tabs.loadBookmarksInTabs设置true。
新标签中打开搜索 browser.search.openintab设置true.</description>
    </item>
    
    <item>
      <title>vscode远程开发应用场景</title>
      <link>https://www.yuedun.wang/blogdetail/5fb757025edb9b37630b808b/</link>
      <pubDate>Fri, 20 Nov 2020 05:41:22 +0000</pubDate>
      
      <guid>https://www.yuedun.wang/blogdetail/5fb757025edb9b37630b808b/</guid>
      <description>vscode远程开发 vscode远程开发功能在2019年5月份发布，到现在已经有一年半的时间了，但是周围的人很少提及此功能，并不是没有人使用vscode，而是对此没有强烈需求。
那么远程开发还有什么用呢？下面我来举些列子。
关于vscode远程环境搭建本文不重复说明，网上有大量教程，大家只需要安装remote development插件基本都可以使用起来。
远程开发，顾名思义就是连接远端服务器进行开发，这样的场景确实不是很常见，但是有时候却是很有用，能够解决燃眉之急。
本地主机性能差 有一些大型项目对电脑的要求也较高，编译耗时，跑起来吃内存，我们的常规解决方案是升级电脑内存，升级硬盘，总之就是换高配电脑，如果是换一台也倒罢了，如果是一个团队都要使用更高配的电脑，那这样的成本还是挺高的。
此时利用远程开发功能，所有人共用一台8核16G服务器就足够了。能够解决编译耗时，吃内存等问题。
开发环境统一 现代大多数应用服务是跑在Linux上的，而开发环境则有Windows，Mac，有些服务在开发环境下无法顺利跑起来，这种情况就可以利用远程开发，不再需要虚拟机或WSL了，在Linux上部署应用，在Windows上开发。
远程调试 远程调试我想很多人都有过这样的需求，但是却从来没有过真正的实践，原因是太难搞了。线上出问题，本地无法复现，真希望能够直接调试线上代码，但是无奈无法实现。现在好了，有了vscode远程开发，调试就变得容易了。
远程编辑文件 在Linux上编辑文件时使用的vim编辑器对大多数人来说有些头大，能在vscode中编辑文本就舒服多了。只需要使用vscode连接远程服务可以很方便打开文件并编辑。
在家临时远程开发 作为开发的我们，每天下班都要背着电脑回家，主要原因就是防止线上有问题，能够打开电脑调试代码。一般来说并不是家里没有电脑，而是没有能够正常运行的开发环境。
而远程开发正好能解决该问题，我们需要的仅仅是一台装有vscode的普通电脑即可，不需要再操心开发环境，各种SDK，C++，Python，Nodejs等等八辈子不用的软件装了一大堆，还需要经常更新才行。
节省成本 大多数开发人员是不需要经常开发大型项目和远程调试代码的，但是不是完全没有，这样就需要为了不时之需而配置笔记本电脑，而笔记本电脑一般相对台式机是又贵性能还低，公司要为了应对偶发情况而给开发人员配备笔记本电脑，会造成资源浪费，成本升高。
如果有了远程开发环境，则能应对临时性工作，大大降低成本。
用iPad写代码 如果你觉得vscode远程开发还不够酷？那在iPad中写代码呢？
vscode远程开发虽好，但还有有局限性，毕竟还是需要一台可以安装vscode的电脑，还是不能随时随地的写代码。现在我要告诉你如何在iPad中写代码！
code-server是一个可以运行在服务器上的web项目，这下我们可以在浏览器中使用vscode了，可以在浏览器中打开vscode的，自然就可以使用iPad来写代码了。 Eclipse Theia https://gitpod.io/#https://github.com/eclipse-theia/theia
额，希望苹果能给我广告费！
再或者使用使用codespaces也可以在线编辑代码，https://mp.weixin.qq.com/s/Eutjgbx_nofmuhU2yBGhxg
最后 贴一篇带图的环境搭建教程真香！使用 VSCode 远程开发调试</description>
    </item>
    
    <item>
      <title>通用的数据库GUI工具</title>
      <link>https://www.yuedun.wang/blogdetail/5fb32fc75edb9b37630b7a6a/</link>
      <pubDate>Tue, 17 Nov 2020 02:04:55 +0000</pubDate>
      
      <guid>https://www.yuedun.wang/blogdetail/5fb32fc75edb9b37630b7a6a/</guid>
      <description>MySQL常用的客户端是Navicat，SQLyog等，本文推荐另一款通用的客户端：DBeaver
DBeaver不能创建表？那是因为选错了视图。可以重新编辑链接</description>
    </item>
    
    <item>
      <title>puppeteer模拟3G网络</title>
      <link>https://www.yuedun.wang/blogdetail/5faa34535edb9b37630b6e99/</link>
      <pubDate>Tue, 10 Nov 2020 06:33:55 +0000</pubDate>
      
      <guid>https://www.yuedun.wang/blogdetail/5faa34535edb9b37630b6e99/</guid>
      <description>puppeteer要模拟3G，4G网络需要利用DevTools Protocol。 Chrome DevTools Protocol
page = await browser.newPage(); // 模拟3g网络  let cdp = await page.target().createCDPSession(); await cdp.send(&amp;#39;Network.emulateNetworkConditions&amp;#39;, { &amp;#39;offline&amp;#39;: false, &amp;#39;downloadThroughput&amp;#39;: 600 * 1024,//(bytes/sec) 3G最高600K/s 4G 最高10M/s  &amp;#39;uploadThroughput&amp;#39;: 600 * 1024,//(bytes/sec)  &amp;#39;latency&amp;#39;: 0 }); await page.setCacheEnabled(false); await page.goto(url); </description>
    </item>
    
    <item>
      <title>postman使用技巧</title>
      <link>https://www.yuedun.wang/blogdetail/5fa0f8e55edb9b37630b65f7/</link>
      <pubDate>Tue, 03 Nov 2020 06:29:57 +0000</pubDate>
      
      <guid>https://www.yuedun.wang/blogdetail/5fa0f8e55edb9b37630b65f7/</guid>
      <description>postman是开发人员必备的接口测试工具，虽然经常使用，但是并不会使用到所有功能，除了简单的接口测试外，它还有很多实用的功能，如果充分利用起来，能使我们的工作事半功倍。
 环境变量的使用 捕获请求和cookie 收藏接口与分享接口 批量测试 编写文档和示例  环境变量的使用 环境变量的作用是使用切换变量的方式代替频繁的环境修改。这样我们只需保存一次测试接口就可以在不同环境下使用。 举例：
环境变量配置
环境变量使用
环境变量切换
捕获请求和cookie 能够直接将浏览器中的请求和cookie同步到postman，省去手动复制请求接口和cookie到postman中。 同时，对于需要登录后使用的接口，postman可以直接使用浏览器的登录状态，而不必复制cookie。 举例： 收藏接口与分享接口 将自己保存的接口分享与他人，直接拿来即可使用。 如果安装了Chrome插件，则可以直接的浏览器中打开链接。使用客户端需要使用import来导入。 批量测试 保存的多个接口批量测试。 编写文档和示例 对于团队协作很有用，接口交流利器。不仅有了请求参数，添加一个example还可以看到接口返回参数。 </description>
    </item>
    
    <item>
      <title>nodejs专用发布系统</title>
      <link>https://www.yuedun.wang/blogdetail/5f41c9d65edb9b37630b0d46/</link>
      <pubDate>Sun, 23 Aug 2020 01:43:50 +0000</pubDate>
      
      <guid>https://www.yuedun.wang/blogdetail/5f41c9d65edb9b37630b0d46/</guid>
      <description>Nodejs项目部署到服务器以后接下来做的最多的操作就是上线发布了。因为nodejs的语言特性决定了其开发效率高，发布自然就频繁，每个公司或个人都有自己的发布方式。
有的公司会有严格的流程，必须通过CI/CD工具进行发布，有可能使用现成的工具，如：jenkins。有可能是自研发布系统。
有的公司会通过FTP上传代码到服务器发布。
有的公司使用更原始的发布方式，直接登录服务拉代码发布。
不论哪种发布方式都有其优缺点，越高级的工具会有诸多限制，比如有权限控制，有严格的审批流程，自然就不能随时发布，也就越僵化。越原始的方式越简单越灵活，自然风险也越高。
至于采用哪种发布方式，依据需要选择即可。
而关于nodejs的发布方式，本人也是也是多种方式都有使用，公司项目也经历过多次变迁。公司最开始是直接登录服务器拉代码发布，后来有了运维团队，领导说开发自己发布不安全，于是就由运维搭建了Jenkins环境来发布，但是每次发布都需要走流程，后来因为发布太频繁，每1-2天要发布一次，又要灰度发布，运维也会觉得烦。于是开发就搭建了某个发布系统自己来发布，不过这个发布系统有个缺点，就是发布集群的时候是串行的，每次发布要十几分钟。
另外说明一下Jenkins。它应该是使用最多的发布系统了，Jenkins基于Java开发，它已经是成熟的系统了，成熟同时也代表着复杂，复杂代表修改困难，我想大家也不太会基于Jenkins定制开发。 然后是部署困难，相比较nodejs三条命令搞定linux安装nodejs——快捷版，go直接放二进制文件部署，Jenkins部署可能就略显复杂了。
于是下定决心自己开发一个发布系统，朱雀发布系统因此诞生。
基于以往的发布系统使用经历，我想要的是一款使用够灵活，部署够简单的发布系统。市面上现有的系统为了满足各种语言的发布，做的大而全。我自然是不想重蹈覆辙再做一个大而全的系统，我要的是小而美。正好之前了解过PM2本身集成了远程发布功能，可以在此基础上开发。PM2本身的发布过程其实已经很简单了，而且足够灵活，能够满足我的部分要求，但是公司的环境是不能在本地直接连接应用服务器的，所以需要一个中间层代理一下，放一张简单的架构图：
和其他工具架构逻辑一样，都是通过ssh来通信，不同的是朱雀没有直接使用ssh，而是利用了pm2,由pm2来实现通信，它已经为了做了一部分工作，比如拉代码，回滚，执行远程脚本。 由于nodejs的项目特性，它依赖了node_modules包，如果按照打包的方式发布会又大又费时，所以还是选择拉git代码的方式发布比较合适。 所以我只需要给它做一个图形界面，并有一定的管理和审批流程（可根据环境跳过）。 放一张图来看一下：
项目地址：nodejs发布系统
朱雀发布系统支持scp（rsync）发布</description>
    </item>
    
    <item>
      <title>人人都值得学习的UI自动化</title>
      <link>https://www.yuedun.wang/blogdetail/5e96f1d8bd7e796e7100a71a/</link>
      <pubDate>Wed, 15 Apr 2020 11:36:56 +0000</pubDate>
      
      <guid>https://www.yuedun.wang/blogdetail/5e96f1d8bd7e796e7100a71a/</guid>
      <description>为什么需要UI自动化？ 说起自动化，听着很厉害，可是也没见识过到底多厉害，基本是属于传说，没见过实战。但不能否认其价值，作者本人作为一个开发者也是偶然的机会接触到UI自动化，感受到了自动化的魅力，才不惜花时间来学习并使用在实际工作中。下面就来说一下为什么要做自动化。 自动化有很多种，单元测试，接口测试，UI测试。所有测试过程可以形成这样一个金字塔：
（图片来自网络）
（图片来自网络）
从图中看出底层测试简单快速，每个单元相对独立，测试成本也较低。而最顶层的UI层聚合了底层的很多接口服务，一个测试流程相对更长更复杂，也就导致了速度慢，成本高的问题。如果由人工来完成，一个完整的测试流程往往需要几分钟，而且是不停的重复这样一个流程。所以很多开发都不愿意完整的测试自己所开发的一套业务，只能由测试人员不厌其烦的循环往复。此时如果有自动化的话就非常nice了。口说无凭，一图胜千言：
是不是还没看清？没错，平时人工测试一个报名表单需要15秒左右，而自动化后几乎一瞬间即可完成，速度提升不言而喻。如果您对UI自动化已产生兴趣，请继续往下看。
哪些场景可以UI自动化？ UI自动化的目的不是为了自动化而自动化，也并不能覆盖所有测试。还是以测试金字塔来说明：
UI自动化虽然只能覆盖到约10%，但其价值却不可忽略，因为越往顶层消耗的人力成本越高，如果底层测试不够充分就只能靠顶层测试来保证。自动化虽好，但需要满足特定的场景才行，那么什么样的场景可以做UI自动化？
 流程变化少。侧重UI的修改，而不是流程的修改。 频繁的回归测试。比如一个报名表单样式修改比较频繁，需要测试其报名是否可用。 界面稳定。样式可以频繁修改，但表单顺序和个数变化较少不能频繁变更。 维护周期长。如果只是使用一次那也不必自动化了，毕竟自动化是解决重复劳动。 开发与测试可相互配合。自动化需要程序有一定规范便于测试人员写测试程序。 测试人员具备编程能力。 如果满足了上述的场景，那么UI自动化在人力消耗和效率上就有很大的提升。正确性上更有保证，手工录入会有输错重输的情况，而自动化则不会出现。 再看一个流程比较长的页面：  上面动图并没与快进，一气呵成完成了一次下单流程，基本不需要停留即可进入下一步，相比起手动操作省时省力。
为什么UI自动化普及率低？ 既然UI自动化能提高效率，但为什么却很少有人去使用？
 开发自动化程序对测试人员的编程水平有一定要求，很少有人愿意花时间去写这个程序。 对于互联网公司，大多数业务需要快速迭代，一个页面的生存周期很短，也可能只是一次性的，自动化测试没有存在的必要性。 测试人员没有切实的感受到效率提升。  其实说白了，就是大家觉得投入和产出不值得。如果是迫于领导压力要写自动化程序，就会不停的对程序修修补补，自己用的话有问题大不了不用自动化，手动测试一下通过就行，如果是给别人用就会不停收到反馈和吐槽，自然也就没有写下去的动力了。 所以个人觉得，自动化程序不应该成为一种流程和形式，而是应该由开发和测试人员自发的去将自身经常重复的工作做成自动化。因为自动化本身就不能覆盖所有场景，只有实际参与的人才能知道哪些是可以自动化的。
有哪些工具可以选择？ 目前市场上不仅提供了多种工具可以选择，还支持不同语言。 web端：selenium、webdriver、robotframework、puppeteer等。 APP端：Appium、Instrumentation、Robotium 、UIAutomator、Espresso、Calabash、Selendroid、Robolectric、RoboSpock、Cafe、Athrun等。
 移动APP自动化测试框架
 本文不对所有工具一一详解，可自行根据平台选择合适的工具和语言进行学习使用。只针对个别WEB端工具做简单说明。 拿selenium来说，selenium是一款很多人比较熟悉的工具，支持的语言有Python，Java，JavaScript等，推荐使用Python。而且其支持的浏览器也很全面： Google Chrome Internet Explorer 7, 8, 9, 10, 11 Firefox Safari Opera HtmlUnit phantomjs Android iOS
一些常见问题 在自动化过程中最多的就是对元素进行定位，自动化工具常见的定位符有：
 id name class name tag link text partial link text xpath css selector  以上这些元素定位对于以前的网页来说还足以应对，因为以前开发的网页大多数元素会有id，class这些属性，定位起来也比较方便。但是对于react，vue，angular这类数据驱动的框架就不那么友好了。 比如有这么一个元素：&amp;lt;div&amp;gt;{{element}}&amp;lt;/div&amp;gt;结果为：</description>
    </item>
    
    <item>
      <title>windows调整C盘大小</title>
      <link>https://www.yuedun.wang/blogdetail/5e38ea905bd8165f28d1fc55/</link>
      <pubDate>Tue, 04 Feb 2020 03:52:48 +0000</pubDate>
      
      <guid>https://www.yuedun.wang/blogdetail/5e38ea905bd8165f28d1fc55/</guid>
      <description>新买的windows笔记本一般会对磁盘进行分区，虽然有说法是现代电脑没必要分区，不过目前很多人还是有这样的习惯。 然而我们往往低估了软件的吃磁盘能力，会把C盘设置50G左右的大小，觉得C盘只是装个系统而已，会自觉把软件装到其他盘下，结果就是没用几个月C盘就满了。其实，虽然我们把软件装到了其他盘，但是软件本身会下载很多内容，比如数据保存，缓存，默认下载等等都会占用C盘。所以建议C盘设置100G比较合理。 关于已经分配好大小的磁盘也可以进行调整，需要借助一些软件来操作，本文作者使用的是Diskgenius。
很简单的三个步骤：
 选择需要扩容的磁盘右击“扩容分区” 选择缩容的磁盘，用于将缩容的磁盘分配给C盘。 选择需要缩容的大小。  确认开始大约需要十几分钟就可以了。</description>
    </item>
    
    <item>
      <title>再聊docker和nodejs</title>
      <link>https://www.yuedun.wang/blogdetail/5a6ab02e260a5391e91a525f/</link>
      <pubDate>Fri, 26 Jan 2018 04:35:58 +0000</pubDate>
      
      <guid>https://www.yuedun.wang/blogdetail/5a6ab02e260a5391e91a525f/</guid>
      <description>上一篇写到了如何在docker中运行nodejs，运行方式是在docker中安装了pm2来保证node服务宕机重启，这种方式更像是把docker当做虚拟机来使用。其实，既然使用了docker的话就可以不使用pm2来管理进程，因为docker自身可以充当守护进程，在node进程退出时进行重启。只要在启动docker容器时加上&amp;ndash;restart=always参数即可。例如：docker run -d --restart=always -p 3000:3000 mynode:1
没有pm2如何开启多进程 使用pm2可以开启多node进程，并且自带负载均衡，但是有个限制，pm2可以开启的进程数是CPU最大核心数。而使用docker的话就不会受限于此了，开启几十个上百个node服务都可以，然后通过nginx实现负载均衡。不过要手动开启几十上百个docker容器那怎么行？让我手动开启3个都很烦了，这时候就需要用到docker编排工具了，比如：Docker Swarm、Kubernetes、docker compose等，可以一键开启多个容器。但是使用编排工具启动docker端口就不确定了，是由编排工具随机开启服务端口的，这又要做到服务注册发现，所以这些工具结合起来使用。
哪一种部署方式支持并发高？ 使用jmeter在本机上进行了简单的并发测试，服务端进行简单的10万次hash计算，使用pm2开启4个实例，docker开启5个实例。docker使用Nginx做负载均衡，单次访问响应时间在1.2s~1.4s之间不等，在200个并发的情况下，两种模式响应时间相差不大，docker模式响应时间略占优势，大概快了0.1s。当并发数在300以上时两者的响应时间都有增加，此时docker部署方式出现了响应失败的情况，pm2就比较稳定了，虽然响应时间增加，但是并未出现过响应失败。 所以在单机上低并发docker还是有点优势，如果在高并发情况下还是pm2更稳定一些。（以上测试是单机上进行，准确性并不高）</description>
    </item>
    
    <item>
      <title>最新版火狐Firefox Quantum 57没有pocket按钮</title>
      <link>https://www.yuedun.wang/blogdetail/5a615ab64bdc8ea471fd2ddd/</link>
      <pubDate>Fri, 19 Jan 2018 02:40:54 +0000</pubDate>
      
      <guid>https://www.yuedun.wang/blogdetail/5a615ab64bdc8ea471fd2ddd/</guid>
      <description>从火狐量子浏览器开始，pocket按钮集成到了地址栏右侧，
如果你找不到，那么有可能是在浏览器配置中关闭了，开启方式：
 地址栏中输入about:config,点击“我了解风险”继续，搜索“pocket.enabled”，如果是false双击修改为true就会出现。
 其他情况可参考：https://help.getpocket.com/article/942-where-is-the-pocket-button-in-firefox</description>
    </item>
    
    <item>
      <title>本地producer和consumer连接不上远程kafka服务</title>
      <link>https://www.yuedun.wang/blogdetail/5a584429752e661009178c06/</link>
      <pubDate>Fri, 12 Jan 2018 05:14:17 +0000</pubDate>
      
      <guid>https://www.yuedun.wang/blogdetail/5a584429752e661009178c06/</guid>
      <description>Hostname and port the broker will advertise to producers and consumers. If not set, it uses the value for &amp;ldquo;listeners&amp;rdquo; if configured. Otherwise, it will use the value returned from java.net.InetAddress.getCanonicalHostName(). advertised.listeners=PLAINTEXT://ip:9092
 打开advertised.listeners=PLAINTEXT://ip:9092配置，ip为kafka服务ip</description>
    </item>
    
    <item>
      <title>推荐在Nodejs使用的java常用技术和工具</title>
      <link>https://www.yuedun.wang/blogdetail/5a430ce84aa3290e95cb0e67/</link>
      <pubDate>Tue, 26 Dec 2017 15:24:12 +0000</pubDate>
      
      <guid>https://www.yuedun.wang/blogdetail/5a430ce84aa3290e95cb0e67/</guid>
      <description>作为Nodejs开发者可能会对java中常用的一些技术工具不太关心，主要原因大概除了语言级别的间隙就是Nodejs相对于java来说比较轻量级，大多用来开发简单系统，用不到其他工具。根据经验来说，开发相同功能的系统，Nodejs的开发周期和代码体量上也会比Java少太多，毕竟java出生年代长，生态丰富，如果不使用几个框架都感觉不是在开发系统。而Nodejs要开发一个web系统基本使用express或koa就差不多够了。所以对于Nodejs开发者来说，分布式，消息队列，远程调用等技术接触就少些。当然，不用这些技术其实也不会有太大影响，但是对于一个有追求有理想的码农来说我们的眼界不应该局限于系统能运行就行。 下面就来介绍一些可以在nodejs中使用的JAVA常用工具和技术。
elasticsearch ElasticSearch（以下简称ES）是一个基于Lucene的搜索服务器。它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful web接口。Elasticsearch是用Java开发的，并作为Apache许可条款下的开放源码发布，是当前流行的企业级搜索引擎。看见了吧，这就是一个使用JAVA开发的全文搜索引擎，到底有什么用呢？就是可以提供像google和百度一样的搜索功能，就算不需要这样功能，也可以用于管理后台的字段搜索，大家知道数据库的搜索效率比较差，有索引的字段还好，没有的就很慢了，这时ES就可以派上用场了，把数据同步进ES,不论查询列表还是以字段搜索都是极快的，是redis缓存的很好补充。
ELK ELK（ElasticSearch,LogStash,Kibana）是三个工具的组合, Logstash是一款轻量级的日志搜集处理框架，可以方便的把分散的、多样化的日志搜集起来，并进行自定义的处理，然后传输到指定的位置，比如某个服务器或者文件。 Kibana是一个使用nodejs开发的web应用，用于查询和操作ES，就是一个ES的图形界面。 如果nodejs系统布署在多台服务器，那么查看日志是件很头疼的事，你不知道请求发送到哪一台服务器，需要挨个查看，如果服务超过5台，这绝对是噩梦。这时候ELK就是很好的解决方案，LogStash收集每一台服务器的日志统一存到ES中，利用ES的优点，查询任何关键字都很快很方便。
消息中间件（kafka） 拿用户注册为例，需要发送邮件，短信，这两个服务之间本没有关联关系，但我们的一贯作风是用户注册的时候调用邮件服务，短信服务，严谨一点会放在事务中操作，假如一个服务失败可能会让事务回滚，所有操作都失败。这是一种情况，另一种情况是如果要再注册后加积分，那么就得改代码，要是有更多服务要添加就得每次改代码发布，启停服务，不送积分了又要删代码，这就是耦合度太高导致的结果。使用消息中间件不仅能保证服务完整性还可以有效解耦，有兴趣可以去了解kafka,rabbitMQ,roketMQ等消息中间件。
远程调用RPC 通俗的来讲就是两台服务器A和B，A服务器直接调用B服务器上的函数，如果没有一个具体事例很难理解A服务器怎么可能调用到B服务器的函数，感兴趣可下载尝试：https://github.com/yuedun/nodejs-grpc 那么为什么要用rpc呢？A服务器要调用B服务的资源直接用http提供接口不就行了吗？其实http也算是一种远程调用，而且也比较简单直观，但是其效率较低，调用成本高，三次握手耗时，甚至请求头的数据量比请求体还大。那么就需要一种更高效的调用协议了——rpc。为什么需要RPC，而不是简单的HTTP接口
总结：以上的这些工具和技术和语言并没有绑定，java可以使用，nodejs也可以使用，推荐理由：投入成本小，使用收益高。</description>
    </item>
    
    <item>
      <title>Dockerfile CMD命令没有执行npm start</title>
      <link>https://www.yuedun.wang/blogdetail/5a1be456da5c711b612f4d39/</link>
      <pubDate>Mon, 27 Nov 2017 10:09:26 +0000</pubDate>
      
      <guid>https://www.yuedun.wang/blogdetail/5a1be456da5c711b612f4d39/</guid>
      <description>Dockerfile
FROM hub.c.163.com/public/nodejs:6.11.0WORKDIR /appCOPY . /appRUN npm installEXPOSE 3000# CMD [&amp;quot;npm&amp;quot;, &amp;quot;start&amp;quot;]ENTRYPOINT [&amp;quot;npm&amp;quot;, &amp;quot;start&amp;quot;] docker ps:
 CONTAINER ID IMAGE COMMAND 59988bd90894 myfd &amp;quot;/bin/sh -c &#39;/usr/...&amp;quot; 在Dockerfile中配置了CMD [&amp;quot;npm&amp;quot;, &amp;quot;start&amp;quot;],docker ps后显示COMMAND为&amp;quot;/bin/sh -c &#39;/usr/...&amp;quot; 改为ENTRYPOINT [&amp;quot;npm&amp;quot;, &amp;quot;start&amp;quot;]就可以了</description>
    </item>
    
    <item>
      <title>windows好用的bash工具——ConEmu</title>
      <link>https://www.yuedun.wang/blogdetail/598aaf0525207f400eeb1b87/</link>
      <pubDate>Wed, 09 Aug 2017 06:43:17 +0000</pubDate>
      
      <guid>https://www.yuedun.wang/blogdetail/598aaf0525207f400eeb1b87/</guid>
      <description>其实git-bash-for-windows这个git bash工具已经很好用了，不过对于平时需要开3-5的bash窗口的我来说就比较烦了，一直要不停的切换窗口，所以想找一款像linux terminal一样可以多开的工具，幸好有这样的工具，那就是ConEmu。
使用前需要一些配置，不配置也没关系，就是使用起来不方便，我是按照的习惯完全配置成了git bash的使用方式。
第一步: 第二步： 配置本地git bash地址（此步骤可适当配置 第三步： 设置ConEmu启动即打开bash而非windows cmd 第四步： 如果前面都没问题，可以设置自动保存打开的窗口，以便下次打开即可使用 最后： 根据个人喜好修改字体等 这样就可以完美使用git bash，不论是自动补全还是颜色主题都和git bash无异。
另外cmder其实也是我使用过的一个不错的工具，同时推荐试用。</description>
    </item>
    
    <item>
      <title>npm ERR! Error: EPERM: operation not permitted</title>
      <link>https://www.yuedun.wang/blogdetail/59532a3233c3c869639761db/</link>
      <pubDate>Wed, 28 Jun 2017 04:01:54 +0000</pubDate>
      
      <guid>https://www.yuedun.wang/blogdetail/59532a3233c3c869639761db/</guid>
      <description>windows下npm install安装依赖的时候出现下面的错误：
npm ERR! Windows_NT 6.1.7601npm ERR! argv &amp;quot;D:\\Program Files\\nodejs\\node.exe&amp;quot; &amp;quot;D:\\Program Files\\nodejs\\node_modules\\npm\\bin\\npm-cli.js&amp;quot; &amp;quot;install&amp;quot; &amp;quot;yog2@1.0.0&amp;quot;npm ERR! node v4.8.0npm ERR! npm v2.15.11npm ERR! path C:\Users\Administrator\AppData\Roaming\npm-cache\images\3.0.0\package.tgz.1683947925npm ERR! code EPERMnpm ERR! errno -4048npm ERR! syscall renamenpm ERR! Error: EPERM: operation not permitted, rename &#39;C:\Users\Administrator\AppData\Roaming\npm-cache\images\3.0.0\package.tgz.1683947925&#39; -&amp;gt; &#39;C:\Users\Administrator\AppData\Roaming\npm-cache\images\3.0.0\package.tgz&#39;npm ERR! at Error (native)npm ERR! { [Error: EPERM: operation not permitted, rename &#39;C:\Users\Administrator\AppData\Roaming\npm-cache\images\3.0.0\package.tgz.1683947925&#39; -&amp;gt; &#39;C:\Users\Administrator\AppData\Roaming\npm-cache\images\3.0.0\package.tgz&#39;]npm ERR! errno: -4048,npm ERR!</description>
    </item>
    
    <item>
      <title>RockMongo使用方法</title>
      <link>https://www.yuedun.wang/blogdetail/591ea6966af6717b614f9b2b/</link>
      <pubDate>Fri, 19 May 2017 08:02:30 +0000</pubDate>
      
      <guid>https://www.yuedun.wang/blogdetail/591ea6966af6717b614f9b2b/</guid>
      <description>RockMongo是一个PHP5写的MongoDB管理工具。
 鉴于百度bce的mongodb数据使用了RockMongo来管理数据，就以此来说明。
查询操作 点击某个collection后的默认画面：
查询界面很简单，关键是怎么写查询语句？
点击文本可以查看所有数据字段，查询title为“测试”文档：
array(&#39;title&#39; =&amp;gt; &#39;测试&#39;)模糊查询：
array(&#39;title&#39;=&amp;gt; new MongoRegex(&amp;quot;/测试/i&amp;quot;))字段名要加引号，中间使用=&amp;gt;而不是使用:分割，需要查询的值也需要注意，字符串加引号，数字不加，如果类型不匹配就会查不出数据。查询结果有一条数据
修改操作 动作中选择“modify”
再查询一下
基本操作就是这样，删除操作不用说也应该能知道怎么做了。</description>
    </item>
    
    <item>
      <title>VMware重新安装VMware Tool</title>
      <link>https://www.yuedun.wang/blogdetail/5742d3bb44b00beb2d26238d/</link>
      <pubDate>Mon, 23 May 2016 09:56:11 +0000</pubDate>
      
      <guid>https://www.yuedun.wang/blogdetail/5742d3bb44b00beb2d26238d/</guid>
      <description>VMware重新安装VMware Tool  将虚拟机从Ubuntu 14重新安装为Ubuntu 16以后不能将Windows的文本内容复制到Linux中，需要重新安装VMware Tool,VMware版本为12
 一、安装VMware Tool 安装时需要在虚拟机启动登录的情况下进行，
点击以后应该会弹出磁盘图标并且打开一个文件夹
文件夹中包含一个压缩文件，需要解压，解压需要root权限，打开命令行 # sudo su 提升为超级用户，可以右击查看gz压缩文件路径，并切换到该目录下，或者可以直接使用图形界面，右击-提取，不能提取到当前目录下，该目录为磁盘目录，不能写入数据，解压到其他目录下即可。解压完成会得到vmware-tools-distrib文件夹，文件夹下有多个文件，其中有vmware-install.pl，命令行中执行这个文件 ./vmware-install.pl 基本可以一路按回车，安装完成后需要重启。重启后可能会有这样的显示，不过不影响。</description>
    </item>
    
    <item>
      <title>webuploader模态框按钮不起作用或每次打开都会变大</title>
      <link>https://www.yuedun.wang/blogdetail/568b2d05db1fef9e0cda949f/</link>
      <pubDate>Tue, 05 Jan 2016 02:40:05 +0000</pubDate>
      
      <guid>https://www.yuedun.wang/blogdetail/568b2d05db1fef9e0cda949f/</guid>
      <description>在bootstra模态框中放置webuploader上传控件，每次打开模态框按钮都会成倍放大，原因是每次打开模态框都会进行一次初始化，在原来按钮的基础上又加了一层样式，那么初始化一次应该可以吧。
修改后的确不会再放大了，可以又有新问题出现了，就是不能点击上传文件了。
上传实例初始化一次，先然按钮正常显示， var uploader = WebUploader.create({})， 再通过uploader提供的API重新添加一个按钮uploader.addButton({})，这样类似于将前一个按钮覆盖了。</description>
    </item>
    
    <item>
      <title>TortoiseGit提交到远程仓库时git did not exit cleanly (exit code 128)</title>
      <link>https://www.yuedun.wang/blogdetail/564554fec888d8070f145c36/</link>
      <pubDate>Fri, 13 Nov 2015 03:11:58 +0000</pubDate>
      
      <guid>https://www.yuedun.wang/blogdetail/564554fec888d8070f145c36/</guid>
      <description>虽然出现git did not exit cleanly (exit code 128)的情况各有不同，不过其中一种是提交时的读写权限有问题，如果本地代码连接的是SSH仓库，那么可能是服务端没有配置SSH Key。github有两个地方配置sshkey，有一个是全局的，另一个是针对单个仓库的，如果给某个仓库配置了Deploy keys（其实和SSHkey一样），提交另一个代码时就会出现git did not exit cleanly。对于我这种不熟练的人来说就想着再添加一个Deploy keys，但是又提示Key already in use，这时就要看看是不是其他仓库单独配置了ssh key。如果仓库太多具体哪个配置了也不太清楚，有个简单快读的办法是在命令行执行 ssh -T -ai .\id_rsa git@github.com，会告诉你哪个仓库在使用本地的id_rsa内容。删掉Deploy keys，配置为全局SSH Keys就行了</description>
    </item>
    
    <item>
      <title>Git SSH Key在windows下生成过程</title>
      <link>https://www.yuedun.wang/blogdetail/56400429c888d8070f145c35/</link>
      <pubDate>Mon, 09 Nov 2015 02:25:45 +0000</pubDate>
      
      <guid>https://www.yuedun.wang/blogdetail/56400429c888d8070f145c35/</guid>
      <description>切换到C:\Users\\.ssh
执行命令：ssh-keygen -t rsa -C &amp;ldquo;邮箱地址&amp;rdquo;
Generating public/private rsa key pair.
Enter file in which to save the key (//.ssh/id_rsa):
第一次生成由于没有id_rsa文件和id_rsa.pub文件，所以需要生成这两个文件，然后手动输入：./id_rsa
Enter file in which to save the key (//.ssh/id_rsa): ./id_rsa，虽然要求输入//.ssh/id_rsa，但这种方式不是在当前目录下
接下来两部是要求输入密码，不输入直接回车就完成了。
PS C:\Users\admin\.ssh&amp;gt; ssh-keygen -t rsa -C &amp;#34;myemail@163.com&amp;#34; Generating public/private rsa key pair. Enter file in which to save the key (//.ssh/id_rsa): ./id_rsa Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in .</description>
    </item>
    
    <item>
      <title>检测网站中未使用的css样式</title>
      <link>https://www.yuedun.wang/blogdetail/563069efaa0d5223f187dfa4/</link>
      <pubDate>Wed, 28 Oct 2015 06:23:43 +0000</pubDate>
      
      <guid>https://www.yuedun.wang/blogdetail/563069efaa0d5223f187dfa4/</guid>
      <description>网站的css样式文件在多次修改后会有很多样式废弃不再使用，使得维护起来困难，还可能出现重名样式，后面的覆盖掉前面的效果，所以有必要清除掉不再使用的样式。可以使用的工具很多，不过在使用了Dust-Me Selectors觉得足够了。
https://addons.mozilla.org/en-US/firefox/addon/dust-me-selectors/
打开上面网址安装
直接点击这个小扫把会检测当前页面没有使用的样式，不过这样的结果还不是我们想要的，因为当前页面没有使用不代表其他页面也没有使用。我们更需要的是找出整个网站中未使用的样式。
选择第一项“Spider Sitemap”，就像是百度蜘蛛爬取整个网站数据一样。
输入网址，本地网址和网络地址都可以检测，点击“Start”后很快就有结果了，如果页面较多会费时些。
可以看到有橘黄色部分就是没有使用的样式，但是这也不能完全代表就是没有使用过，上面三个未使用的样式是我对于博客内容的图片和引用块使用的样式，因为本地的测试内容中的确没有使用这三个样式，但是线上的网站却使用了，遇到这种情况就需要仔细甄别了。
再看一下扫描的页面日志
基本的页面都有扫描过了。此时可以手动删除掉没有使用的样式，这个插件对于简单的网站够用了，但是大型网站就不准确了，当然有些其他工具还可以导出检测后的结果。有必要的可以去下载。</description>
    </item>
    
    <item>
      <title>linux下添加svn用户名密码</title>
      <link>https://www.yuedun.wang/blogdetail/562d9ca9c6ed32d312337025/</link>
      <pubDate>Mon, 26 Oct 2015 03:23:21 +0000</pubDate>
      
      <guid>https://www.yuedun.wang/blogdetail/562d9ca9c6ed32d312337025/</guid>
      <description>首先需要知道配置文件的位置，比如我们的服务器中我就找到很多关于svn的目录，甚至分不清哪个目录下才是真正的配置文件
root@handou:~# find / -name subversion
/home/handou/workspace/subversion-1.8.11/subversion
/home/handou/workspace/subversion-1.8.11/subversion/bindings/javahl/src/org/apache/subversion
/home/handou/workspace/subversion-1.8.11/subversion/bindings/javahl/src/org/tigris/subversion
/home/handou/workspace/subversion-1.8.11/subversion/bindings/javahl/tests/org/apache/subversion
/home/handou/workspace/subversion-1.8.11/subversion/bindings/javahl/tests/org/tigris/subversion
/etc/bash_completion.d/subversion
/etc/subversion
/usr/share/doc/subversion
查找所得结果可以确定应该是在 /etc/subversion下，切换到subversion下有多个文件：
config config.dpkg-dist dav_svn.authz dav_svn.passwd passwd servers
可能需要一一查看下都是什么内容，其实主要是dav_svn.authz dav_svn.passwd这两个文件，一个存放用户名，一个存放密码，dav_svn.authz内容包含账号和权限：
[groups]
apiadmin=yuedun
[handou:/]
@admin=rw
@apiadmin=rw
可以编辑这个文件添加账号，然后添加密码，但是不能直接编辑dav_svn.passwd，这里面是加密数据，需要使用Apache的htpasswd命令添加。
htpasswd /etc/subversion/dav_svn.passwd &amp;lt;用户名&amp;gt;
然后会提示输入密码，就此完成svn账号设置。</description>
    </item>
    
    <item>
      <title>手机和PC联机调试Debugging Firefox for Android with WebIDE</title>
      <link>https://www.yuedun.wang/blogdetail/56286fd6ce46c19e89132969/</link>
      <pubDate>Thu, 22 Oct 2015 05:10:46 +0000</pubDate>
      
      <guid>https://www.yuedun.wang/blogdetail/56286fd6ce46c19e89132969/</guid>
      <description>Firefox提供了在PC端调试手机端页面的工具，详情查看： https://developer.mozilla.org/zh-CN/docs/Tools/Remote_Debugging/Debugging_Firefox_for_Android_with_WebIDE</description>
    </item>
    
    <item>
      <title>使用sublime开发node.js快速跳转到变量函数声明处</title>
      <link>https://www.yuedun.wang/blogdetail/56286643ce46c19e89132968/</link>
      <pubDate>Thu, 22 Oct 2015 04:29:55 +0000</pubDate>
      
      <guid>https://www.yuedun.wang/blogdetail/56286643ce46c19e89132968/</guid>
      <description>开发中最常用的操作之一就是快速跳转到变量，方法声明处，比如在eclipse中按住Ctrl键鼠标点击变量或方法就能跳转到对应的位置或文件中，开发nodejs程序当然也需要这样的功能，比较强大的开发工具有webstorm，也是支持这种操作的。不过webstorm太占内存，4G的内存下总是提示内存不足，需要关闭占用内存程序，而首当其冲的就是webstorm，所以最近试了试另一款被大家熟知和推荐的开发神器sublime。虽然sublime是个文本编辑器，还不能算的上IDE，不过它可以安装各种插件来丰富功能，最重要的是它占用内存少，速度快。
所以，我要介绍的是在ST下如何做到跳转到变量或方法声明处。
首先在uses.js文件中有一个函数
//我是一个测试方法  router.get(&amp;#34;/commeHere&amp;#34;, function(req, res) { }); 然后我要从其他文件中跳转到这个函数。先关掉这个文件，打开其他文件。
可以双击或鼠标选中commeHere这个关键词（才发现单词打错了），键盘按下Ctrl+shift+F就会出现类似搜索框，选中的关键字会填充到find框中，需要手动选择where框，选择Add Open Folders，文本框中填充的就是，然后回车就可以了，很快就会搜索出我们需要的关键字所在的文件。
双击就可以跳转到对应的文件和行上。
当然，不可能像eclipse中那么方便，但其实只有两步操作，第一ctrl+shift+F搜索关键字，第二双击搜索结果跳转到对应文件位置。如果你习惯使用ST的话肯定很满足这样的设计，根本不会觉得繁琐。</description>
    </item>
    
    <item>
      <title>微信开发通过公网访问本地服务器</title>
      <link>https://www.yuedun.wang/blogdetail/55ab0f6ed366f15412cbf596/</link>
      <pubDate>Sun, 19 Jul 2015 02:46:06 +0000</pubDate>
      
      <guid>https://www.yuedun.wang/blogdetail/55ab0f6ed366f15412cbf596/</guid>
      <description>做微信开发的时候，在开发者中心需要进行服务器配置，这里的配置是一个可以公网访问的地址，如果是产品上线的话肯定有公网地址，但是在开发过程中需要本地测试，总不能开发一点部署到服务器测试。这时候我们就需要从公网访问本地服务器。
这已经是设置好的，服务器端口是指公网地址的端口，就以80端口来好了，这样公网地址可以省略端口，内部服务器端口就是本地服务器端口，Java程序一般是8080这样的端口，IP地址就是本地服务器在局域网中的ip，协议选ALL，状态：生效。常用服务器端口可以不选。
然后启动本地服务器就可以通过路由器的公网IP访问本地服务了
但是我们不习惯使用IP地址访问，可以通过域名来访问，首先再到路由器中配置“动态DNS”： 当然，得先注册一个动态域名，登录成功之后就可以通过域名访问本地应用服务器了 </description>
    </item>
    
    <item>
      <title>搞懂了七牛文件存储</title>
      <link>https://www.yuedun.wang/blogdetail/54662bf3e8183bcf964f88eb/</link>
      <pubDate>Fri, 14 Nov 2014 16:21:07 +0000</pubDate>
      
      <guid>https://www.yuedun.wang/blogdetail/54662bf3e8183bcf964f88eb/</guid>
      <description>由于工作没时间，博客搭建起来以后一直没有添加文件上传功能，瞬间感觉不完美了。这两天外包项目结束，要出项目组，在交接工作之余，用中午休息时间写好了文件上传功能，具体是图片上传。在本地测试好发布到BAE上，居然没法上传了，初步推断应该是服务器没有写权限，原来一直想试试百度云存储来做图片存储，但是翻看了文档发现暂不支持node.js上传，只能先上传好再引用链接，感觉好麻烦。由于一直在node中文社区混，发现用的是七牛存储，也想跟着大牛的步伐去试试，对开发文档进行两轮战斗，愣是没看懂，今天没事干，就从头到尾认认真真看了一遍，动手写了个测试程序，可以上传，激动万分，真想分享出来，但是测试程序还不完善，还没有把回调搞定，也没有完整的例子拿出来给大家看，等完全搞定了以后再写个教程卖弄一下。 </description>
    </item>
    
    <item>
      <title>git常用命令</title>
      <link>https://www.yuedun.wang/blogdetail/54486c117b1470fa64bb911a/</link>
      <pubDate>Thu, 23 Oct 2014 02:46:41 +0000</pubDate>
      
      <guid>https://www.yuedun.wang/blogdetail/54486c117b1470fa64bb911a/</guid>
      <description>查看、添加、提交、删除、找回，重置修改文件
git help # 显示command的help
git show # 显示某次提交的内容 git show $id
git co &amp;ndash; # 抛弃工作区修改
git co . # 抛弃工作区修改
git add # 将工作文件修改提交到本地暂存区
git add . # 将所有修改过的工作文件提交暂存区
git rm # 从版本库中删除文件
git rm &amp;ndash;cached # 从版本库中删除文件，但不删除文件
git reset # 从暂存区恢复到工作文件
git reset &amp;ndash; . # 从暂存区恢复到工作文件
git reset &amp;ndash;hard # 恢复最近一次提交过的状态，即放弃上次提交后的所有本次修改
git ci git ci . git ci -a # 将git add, git rm和git ci等操作都合并在一起做　git ci -am &amp;ldquo;some comments&amp;rdquo;</description>
    </item>
    
  </channel>
</rss>
